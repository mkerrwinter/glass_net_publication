import numpy as npimport pandas as pddef unpickle(file):    import pickle    with open(file, 'rb') as fo:        dict = pickle.load(fo, encoding='bytes')    return dictbase_path = './'path = '{}data/CIFAR_10/'.format(base_path)files = ['data_batch_1',         'data_batch_2',         'data_batch_3',         'data_batch_4',         'data_batch_5']# Do training set firstdata_list = []labels_list = []for count, file in enumerate(files):    data_dict = unpickle(path+file)        data = data_dict[b'data']    labels = data_dict[b'labels']        data_list.append(data.copy())    labels_list.append(labels.copy())    combined_data = np.concatenate(data_list, axis=0)combined_labels = np.concatenate(labels_list, axis=0)combined_labels = np.expand_dims(combined_labels, axis=1) training_set_array = np.concatenate([combined_labels, combined_data], axis=1)col_names = ['label']for k in range(combined_data.shape[1]):    name = 'pixel_{}'.format(k)    col_names.append(name)training_set = pd.DataFrame(training_set_array, columns=col_names)# Do testing settest_dict = unpickle(path+'test_batch')data = test_dict[b'data']labels = test_dict[b'labels']labels = np.expand_dims(labels, axis=1)testing_set_array = np.concatenate([labels, data], axis=1)testing_set = pd.DataFrame(testing_set_array, columns=col_names)# Save as CSVtraining_set.to_csv(path+'CIFAR_10_train.csv', index=False)testing_set.to_csv(path+'CIFAR_10_test.csv', index=False)